{"cells":[{"cell_type":"markdown","source":["# README\n","You another 2 options to get the models.\n","\n","1. TO SAVE TIME... Download the pre-trained models [https://drive.google.com/drive/folders/1HbQebUjSVBHxFeIeK8WWoDJI8xEG1MHD?usp=sharing]\n","  - Place the .keras files inside a 'Models' folder of the project directory.\n","\n","2. OR follow the instructions up to the 'Modeling' section and train the models yourself.\n","\n","Then, you can start testing the model performances in the 'Performances' section."],"metadata":{"id":"Xwha4FKhdEQ0"}},{"cell_type":"markdown","metadata":{"id":"L-4NEAcb5sTf"},"source":["# Choose Root Directory\n","Uncomment the directory of your choice\n","- Mount Google Drive's root_dir\n","- OR define your own root_dir\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwOX1i4NGXoY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a2db7806-53d9-457d-c55e-d07cd9b31894"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# ----- Google Colab directory and runtime -----\n","from google.colab import drive\n","drive.mount('/content/drive')\n","root_dir = '/content/drive/MyDrive/'\n","\n","# ----- Custom directory, using MAGIC or local runtime -----\n","#root_dir = './'\n"]},{"cell_type":"markdown","metadata":{"id":"fXJpfi1R7AQC","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["# Format Histograms\n","- Need to run before training and/or testing!"]},{"cell_type":"markdown","metadata":{"id":"SP8zoYANqAgX","tags":[]},"source":["## H-Voice"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPwPjE9DqNOF","outputId":"2c83c794-6b49-4e89-f38a-e5c5f6a5f42a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4109 images belonging to 2 classes.\n","Found 1728 images belonging to 2 classes.\n","Found 836 images belonging to 2 classes.\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","\n","# ---------- Format training set ---------- #\n","train_dir = root_dir + 'Voice_Cloning_Detection/Data/H-Voice/Training_Set'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,        # Normalize pixel values to [0, 1]\n","    horizontal_flip=True,  # Enable horizontal flip augmentation for training data\n",")\n","\n","# Flow training images in batches of 32 using train_datagen generator\n","train_generator_HVoice = train_datagen.flow_from_directory(\n","    train_dir,              # Path to the training directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format validation set ---------- #\n","validation_dir = root_dir + 'Voice_Cloning_Detection/Data/H-Voice/Validation_Set'\n","\n","valid_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","valid_generator_HVoice = valid_datagen.flow_from_directory(\n","    validation_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format test set ---------- #\n","test_dir = root_dir + 'Voice_Cloning_Detection/Data/H-Voice/Test_Set'\n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","test_generator_HVoice = test_datagen.flow_from_directory(\n","    test_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")"]},{"cell_type":"markdown","metadata":{"id":"BZ2YQ9HPrm1J","tags":[]},"source":["## SiF-DeepVC - Regular"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1a2hhtKrrpm","outputId":"2d91a229-c0c7-4e95-bc9c-e3d9aa559621"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 7030 images belonging to 2 classes.\n","Found 1357 images belonging to 2 classes.\n","Found 1350 images belonging to 2 classes.\n","Found 1000 images belonging to 1 classes.\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","\n","# ---------- Format training set ---------- #\n","train_dir = root_dir + 'Voice_Cloning_Detection/Data/SiF-DeepVC/Training_Set'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,        # Normalize pixel values to [0, 1]\n","    horizontal_flip=True,  # Enable horizontal flip augmentation for training data\n",")\n","\n","# Flow training images in batches of 32 using train_datagen generator\n","train_generator_SiF_reg = train_datagen.flow_from_directory(\n","    train_dir,              # Path to the training directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format validation set ---------- #\n","validation_dir = root_dir + 'Voice_Cloning_Detection/Data/SiF-DeepVC/Validation_Set'\n","\n","valid_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","valid_generator_SiF_reg = valid_datagen.flow_from_directory(\n","    validation_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format test set ---------- #\n","test_dir = root_dir + 'Voice_Cloning_Detection/Data/SiF-DeepVC/Test_Set'\n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","test_generator_SiF_reg = test_datagen.flow_from_directory(\n","    test_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format deep4s test set ---------- #\n","deep4s_dir = root_dir + 'Voice_Cloning_Detection/Data/SiF-DeepVC/Deep4SNet_Target_Test_Set'\n","\n","deep4s_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","deep4s_generator_SiF_reg = deep4s_datagen.flow_from_directory(\n","    deep4s_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")"]},{"cell_type":"markdown","metadata":{"id":"tppoDtKQqKEb","tags":[]},"source":["## SiF-DeepVC - Filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6LZz2-ow8Ovq","outputId":"5030f988-3901-47ea-f4e4-effcd84c5bf3","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 6303 images belonging to 2 classes.\n","Found 1351 images belonging to 2 classes.\n","Found 1350 images belonging to 2 classes.\n","Found 1000 images belonging to 1 classes.\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","\n","# ---------- Format training set ---------- #\n","train_dir = root_dir + 'Voice_Cloning_Detection/Data/SiF-DeepVC/Training_Set_Filtered'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,        # Normalize pixel values to [0, 1]\n","    horizontal_flip=True,  # Enable horizontal flip augmentation for training data\n",")\n","\n","# Flow training images in batches of 32 using train_datagen generator\n","train_generator_SiF_filtered = train_datagen.flow_from_directory(\n","    train_dir,              # Path to the training directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format validation set ---------- #\n","validation_dir = root_dir + 'Voice_Cloning_Detection/Data/SiF-DeepVC/Validation_Set_Filtered'\n","\n","valid_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","valid_generator_SiF_filtered = valid_datagen.flow_from_directory(\n","    validation_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format test set ---------- #\n","test_dir = root_dir + 'Voice_Cloning_Detection/Data/SiF-DeepVC/Test_Set_Filtered'\n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","test_generator_SiF_filtered = test_datagen.flow_from_directory(\n","    test_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format deep4s test set ---------- #\n","deep4s_dir = root_dir + 'Voice_Cloning_Detection/Data/SiF-DeepVC/Deep4SNet_Target_Test_Set_Filtered'\n","\n","deep4s_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","deep4s_generator_SiF_filtered = deep4s_datagen.flow_from_directory(\n","    deep4s_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")"]},{"cell_type":"markdown","source":["## H-Voice + SiF-DeepVC - Regular"],"metadata":{"id":"1Ebnj90fWhHR"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","\n","# ---------- Format training set ---------- #\n","train_dir = root_dir + 'Voice_Cloning_Detection/Data/H-Voice_SiF-Regular/Training_Set'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,        # Normalize pixel values to [0, 1]\n","    horizontal_flip=True,  # Enable horizontal flip augmentation for training data\n",")\n","\n","# Flow training images in batches of 32 using train_datagen generator\n","train_generator_HVoice_SiF_Reg = train_datagen.flow_from_directory(\n","    train_dir,              # Path to the training directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format validation set ---------- #\n","validation_dir = root_dir + 'Voice_Cloning_Detection/Data/H-Voice_SiF-Regular/Validation_Set'\n","\n","valid_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","valid_generator_HVoice_SiF_Reg = valid_datagen.flow_from_directory(\n","    validation_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format test set ---------- #\n","test_dir = root_dir + 'Voice_Cloning_Detection/Data/H-Voice_SiF-Regular/Test_Set'\n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","test_generator_HVoice_SiF_Reg = test_datagen.flow_from_directory(\n","    test_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PvXJhOkOWud9","outputId":"931710ae-9399-457d-9d01-10deb31752b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8300 images belonging to 2 classes.\n","Found 3078 images belonging to 2 classes.\n","Found 2186 images belonging to 2 classes.\n"]}]},{"cell_type":"markdown","source":["## H-Voice + SiF-DeepVC (Filtered)"],"metadata":{"id":"SMcI-Bt1wMJQ"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","\n","# ---------- Format training set ---------- #\n","train_dir = root_dir + 'Voice_Cloning_Detection/Data/H-Voice_SiF-Filtered/Training_Set'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,        # Normalize pixel values to [0, 1]\n","    horizontal_flip=True,  # Enable horizontal flip augmentation for training data\n",")\n","\n","# Flow training images in batches of 32 using train_datagen generator\n","train_generator_HVoice_SiF_Filtered = train_datagen.flow_from_directory(\n","    train_dir,              # Path to the training directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format validation set ---------- #\n","validation_dir = root_dir + 'Voice_Cloning_Detection/Data/H-Voice_SiF-Filtered/Validation_Set'\n","\n","valid_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","valid_generator_HVoice_SiF_Filtered = valid_datagen.flow_from_directory(\n","    validation_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")\n","\n","\n","# ---------- Format test set ---------- #\n","test_dir = root_dir + 'Voice_Cloning_Detection/Data/H-Voice_SiF-Filtered/Test_Set'\n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",")\n","\n","# Flow validation images in batches of 32 using valid_datagen generator\n","test_generator_HVoice_SiF_Filtered = test_datagen.flow_from_directory(\n","    test_dir,         # Path to the validation directory\n","    target_size=(150, 150), # Resize images to 150x150 pixels\n","    batch_size=32,\n","    class_mode='binary'     # Assuming binary classification\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"924avB0gwTYm","outputId":"3a0f08e8-a40f-4dbe-e591-440f5a85ae51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8357 images belonging to 2 classes.\n","Found 3078 images belonging to 2 classes.\n","Found 2186 images belonging to 2 classes.\n"]}]},{"cell_type":"markdown","metadata":{"id":"LugK-d2v-S5k","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["# Modeling (ONLY RUN ONCE)\n","- Run once to save the models as keras files\n","- Deep4SNet CNN\n","- https://www.sciencedirect.com/science/article/pii/S0957417421008770"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOWsX5y7-o_b"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import RMSprop\n","\n","# Define the Deep4SNet CNN model\n","def create_cnn_model(input_shape, num_classes):\n","    model = Sequential([\n","        Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='random_normal', bias_initializer='zeros'),\n","        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n","\n","        Conv2D(32, (3, 3), strides=(1, 1), activation='relu'),\n","        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n","\n","        Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),\n","        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n","\n","        Flatten(),\n","        Dense(64, activation='relu'),\n","        Dropout(0.2),\n","        Dense(num_classes, activation='sigmoid')  # Output layer\n","    ])\n","    return model\n","\n","# Adjusted model with increased depth and dropout rates\n","def increased_dropout(input_shape, num_classes):\n","    model = Sequential([\n","        Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='random_normal', bias_initializer='zeros'),\n","        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n","        Dropout(0.3),  # Increased dropout rate\n","\n","        Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),\n","        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n","        Dropout(0.4),  # Increased dropout rate\n","\n","        Conv2D(128, (3, 3), strides=(1, 1), activation='relu'),\n","        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n","        Dropout(0.4),  # Increased dropout rate\n","\n","        Flatten(),\n","        Dense(128, activation='relu'),\n","        Dropout(0.5),  # Keep dropout rate for the dense layer\n","        Dense(num_classes, activation='sigmoid')\n","    ])\n","    return model\n","\n","# Adjusted model with increased depth\n","def deeper_model(input_shape, num_classes):\n","    model = Sequential([\n","        Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='random_normal', bias_initializer='zeros'),\n","        Conv2D(32, (3, 3), strides=(1, 1), activation='relu'),\n","        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n","\n","        Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n","        Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),\n","        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n","\n","        Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n","        Conv2D(128, (3, 3), strides=(1, 1), activation='relu'),\n","        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n","\n","        Flatten(),\n","        Dense(256, activation='relu'),\n","        Dropout(0.5),\n","        Dense(num_classes, activation='sigmoid')\n","    ])\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"8CDdpwbLWWxP","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## Original - H-Voice\n","- https://github.com/yohannarodriguez/Deep4SNet\n","\n","Download the 2 following files:\n","- model_deep4SNet.h5\n","- weights_Deep4SNet.h5\n","\n","After:\n","- Run the code to create the folder that will hold the files\n","- Place both .h5 files inside the folder named 'Deep4SNet-Original-HVoice' in the model_dir"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OWplzaqWe3n","tags":[]},"outputs":[],"source":["import os\n","\n","model_dir = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Original-HVoice'\n","if not os.path.exists(model_dir):\n","    os.makedirs(model_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1e_w2XMGXob","outputId":"f51b8b38-d736-464d-d8a9-5bfe72c6497d"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From C:\\Users\\z1297\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n","TensorFlow version: 2.15.0\n","Keras version: 2.15.0\n"]}],"source":["# Check version\n","\n","import tensorflow as tf\n","import keras\n","\n","# Original Model built on\n","# TensorFlow version: 2.15.0\n","# Keras version: 2.15.0\n","print(\"TensorFlow version:\", tf.__version__)\n","print(\"Keras version:\", keras.__version__)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"3AcvQeI3GXoc"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Original-HVoice/model_Deep4SNet.h5'\n","weights_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Original-HVoice/weights_Deep4SNet.h5'\n","\n","model_original_HVoice = load_model(model_path)\n","model_original_HVoice.load_weights(weights_path)\n","\n","# Save as keras model for moving between computers\n","model_original_HVoice.save(root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Original-HVoice.keras')"]},{"cell_type":"markdown","metadata":{"id":"1bmQ901jpe1r","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## Our - H-Voice\n","- Closest imitation to the loaded original model\n","- Trained on H-Voice histograms"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJEIuQuMpq9i","outputId":"dafa26f6-40f6-4970-9ccc-ada2bbcd4437","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","129/129 [==============================] - 1445s 11s/step - loss: 0.7038 - accuracy: 0.5106\n","Epoch 2/10\n","129/129 [==============================] - 17s 134ms/step - loss: 0.6624 - accuracy: 0.5904\n","Epoch 3/10\n","129/129 [==============================] - 17s 132ms/step - loss: 0.4261 - accuracy: 0.8209\n","Epoch 4/10\n","129/129 [==============================] - 18s 137ms/step - loss: 0.2728 - accuracy: 0.9056\n","Epoch 5/10\n","129/129 [==============================] - 17s 131ms/step - loss: 0.2193 - accuracy: 0.9260\n","Epoch 6/10\n","129/129 [==============================] - 17s 132ms/step - loss: 0.1956 - accuracy: 0.9321\n","Epoch 7/10\n","129/129 [==============================] - 18s 138ms/step - loss: 0.1839 - accuracy: 0.9387\n","Epoch 8/10\n","129/129 [==============================] - 17s 134ms/step - loss: 0.1733 - accuracy: 0.9421\n","Epoch 9/10\n","129/129 [==============================] - 17s 133ms/step - loss: 0.1599 - accuracy: 0.9472\n","Epoch 10/10\n","129/129 [==============================] - 17s 133ms/step - loss: 0.1500 - accuracy: 0.9491\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 150, 150, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 75, 75, 32)        0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 73, 73, 32)        9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 36, 36, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 17, 17, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 18496)             0         \n","                                                                 \n"," dense (Dense)               (None, 64)                1183808   \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1212513 (4.63 MB)\n","Trainable params: 1212513 (4.63 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# Model params\n","input_shape = (150, 150, 3)\n","num_classes = 1 # Number of outputs per input\n","\n","# Model trained on training set\n","model_our_HVoice = create_cnn_model(input_shape, num_classes)\n","model_our_HVoice.compile(optimizer=RMSprop(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model_our_HVoice.fit(train_generator_HVoice, epochs=10)\n","model_our_HVoice.summary()  # Print model summary\n","\n","# Save model\n","model_dir = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice.keras'\n","#if not os.path.exists(model_dir):\n","#    os.makedirs(model_dir)\n","model_our_HVoice.save(model_dir)"]},{"cell_type":"markdown","source":["## Our - H-Voice - Dropout"],"metadata":{"id":"lsdLY8yfEu7L"}},{"cell_type":"code","source":["# H-Voice\n","input_shape = (150, 150, 3)\n","num_classes = 1 # Number of outputs per input\n","\n","# Model trained on training set\n","H_voice_drop = increased_dropout(input_shape, num_classes)\n","H_voice_drop.compile(optimizer=RMSprop(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","H_voice_drop.fit(train_generator_HVoice, epochs=10)\n","H_voice_drop.summary()  # Print model summary\n","H_voice_drop.save(root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice-Dropout.keras')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Xe2AHqYGEE1","outputId":"2715fe68-ac5d-4822-9132-cfbab638e1c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","129/129 [==============================] - 20s 132ms/step - loss: 0.8444 - accuracy: 0.5057\n","Epoch 2/10\n","129/129 [==============================] - 18s 139ms/step - loss: 0.6953 - accuracy: 0.5062\n","Epoch 3/10\n","129/129 [==============================] - 17s 132ms/step - loss: 0.6936 - accuracy: 0.5352\n","Epoch 4/10\n","129/129 [==============================] - 18s 136ms/step - loss: 0.6853 - accuracy: 0.5505\n","Epoch 5/10\n","129/129 [==============================] - 17s 131ms/step - loss: 0.5703 - accuracy: 0.7067\n","Epoch 6/10\n","129/129 [==============================] - 18s 138ms/step - loss: 0.4354 - accuracy: 0.8073\n","Epoch 7/10\n","129/129 [==============================] - 18s 137ms/step - loss: 0.3625 - accuracy: 0.8540\n","Epoch 8/10\n","129/129 [==============================] - 18s 138ms/step - loss: 0.3039 - accuracy: 0.8861\n","Epoch 9/10\n","129/129 [==============================] - 17s 133ms/step - loss: 0.2691 - accuracy: 0.8992\n","Epoch 10/10\n","129/129 [==============================] - 17s 135ms/step - loss: 0.2503 - accuracy: 0.9107\n","Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_12 (Conv2D)          (None, 150, 150, 64)      1792      \n","                                                                 \n"," max_pooling2d_12 (MaxPooli  (None, 75, 75, 64)        0         \n"," ng2D)                                                           \n","                                                                 \n"," dropout_4 (Dropout)         (None, 75, 75, 64)        0         \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 73, 73, 64)        36928     \n","                                                                 \n"," max_pooling2d_13 (MaxPooli  (None, 36, 36, 64)        0         \n"," ng2D)                                                           \n","                                                                 \n"," dropout_5 (Dropout)         (None, 36, 36, 64)        0         \n","                                                                 \n"," conv2d_14 (Conv2D)          (None, 34, 34, 128)       73856     \n","                                                                 \n"," max_pooling2d_14 (MaxPooli  (None, 17, 17, 128)       0         \n"," ng2D)                                                           \n","                                                                 \n"," dropout_6 (Dropout)         (None, 17, 17, 128)       0         \n","                                                                 \n"," flatten_4 (Flatten)         (None, 36992)             0         \n","                                                                 \n"," dense_8 (Dense)             (None, 128)               4735104   \n","                                                                 \n"," dropout_7 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_9 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 4847809 (18.49 MB)\n","Trainable params: 4847809 (18.49 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Our - H-Voice - Deep"],"metadata":{"id":"S7zoaws7LHqE"}},{"cell_type":"code","source":["# H-Voice\n","input_shape = (150, 150, 3)\n","num_classes = 1 # Number of outputs per input\n","\n","# Model trained on training set\n","H_voice_deep = deeper_model(input_shape, num_classes)\n","H_voice_deep.compile(optimizer=RMSprop(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","H_voice_deep.fit(train_generator_HVoice, epochs=10)\n","H_voice_deep.summary()  # Print model summary\n","H_voice_deep.save(root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice-Deep.keras')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMXKB58tLNUq","outputId":"2d2b868f-8cf1-464f-cd47-a3f09decb05e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","129/129 [==============================] - 20s 134ms/step - loss: 0.6980 - accuracy: 0.4957\n","Epoch 2/10\n","129/129 [==============================] - 18s 138ms/step - loss: 0.6976 - accuracy: 0.5011\n","Epoch 3/10\n","129/129 [==============================] - 17s 133ms/step - loss: 0.6936 - accuracy: 0.4982\n","Epoch 4/10\n","129/129 [==============================] - 17s 135ms/step - loss: 0.6934 - accuracy: 0.4996\n","Epoch 5/10\n","129/129 [==============================] - 17s 131ms/step - loss: 0.6931 - accuracy: 0.5079\n","Epoch 6/10\n","129/129 [==============================] - 17s 132ms/step - loss: 0.6931 - accuracy: 0.5057\n","Epoch 7/10\n","129/129 [==============================] - 17s 134ms/step - loss: 0.6933 - accuracy: 0.5096\n","Epoch 8/10\n","129/129 [==============================] - 17s 132ms/step - loss: 0.6931 - accuracy: 0.5128\n","Epoch 9/10\n","129/129 [==============================] - 17s 133ms/step - loss: 0.6934 - accuracy: 0.5069\n","Epoch 10/10\n","129/129 [==============================] - 17s 135ms/step - loss: 0.6930 - accuracy: 0.5082\n","Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_36 (Conv2D)          (None, 150, 150, 32)      896       \n","                                                                 \n"," conv2d_37 (Conv2D)          (None, 148, 148, 32)      9248      \n","                                                                 \n"," max_pooling2d_27 (MaxPooli  (None, 74, 74, 32)        0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_38 (Conv2D)          (None, 74, 74, 64)        18496     \n","                                                                 \n"," conv2d_39 (Conv2D)          (None, 72, 72, 64)        36928     \n","                                                                 \n"," max_pooling2d_28 (MaxPooli  (None, 36, 36, 64)        0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_40 (Conv2D)          (None, 36, 36, 128)       73856     \n","                                                                 \n"," conv2d_41 (Conv2D)          (None, 34, 34, 128)       147584    \n","                                                                 \n"," max_pooling2d_29 (MaxPooli  (None, 17, 17, 128)       0         \n"," ng2D)                                                           \n","                                                                 \n"," flatten_9 (Flatten)         (None, 36992)             0         \n","                                                                 \n"," dense_18 (Dense)            (None, 256)               9470208   \n","                                                                 \n"," dropout_24 (Dropout)        (None, 256)               0         \n","                                                                 \n"," dense_19 (Dense)            (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 9757473 (37.22 MB)\n","Trainable params: 9757473 (37.22 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"gtJn2rwv39kh","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## Our - SiF-DeepVC - Filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6eTY-b5J4ANl","tags":[],"outputId":"61efcee8-2e59-4a71-e40c-f32e6ec616a7","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","197/197 [==============================] - 1559s 8s/step - loss: 0.6231 - accuracy: 0.6397\n","Epoch 2/10\n","197/197 [==============================] - 53s 271ms/step - loss: 0.3446 - accuracy: 0.8610\n","Epoch 3/10\n","197/197 [==============================] - 53s 270ms/step - loss: 0.2453 - accuracy: 0.9118\n","Epoch 4/10\n","197/197 [==============================] - 53s 271ms/step - loss: 0.2088 - accuracy: 0.9221\n","Epoch 5/10\n","197/197 [==============================] - 53s 270ms/step - loss: 0.1933 - accuracy: 0.9340\n","Epoch 6/10\n","197/197 [==============================] - 53s 270ms/step - loss: 0.1853 - accuracy: 0.9334\n","Epoch 7/10\n","197/197 [==============================] - 53s 269ms/step - loss: 0.1729 - accuracy: 0.9384\n","Epoch 8/10\n","197/197 [==============================] - 53s 270ms/step - loss: 0.1669 - accuracy: 0.9386\n","Epoch 9/10\n","197/197 [==============================] - 53s 269ms/step - loss: 0.1598 - accuracy: 0.9435\n","Epoch 10/10\n","197/197 [==============================] - 53s 270ms/step - loss: 0.1583 - accuracy: 0.9442\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 150, 150, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 75, 75, 32)        0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 73, 73, 32)        9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 36, 36, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 17, 17, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 18496)             0         \n","                                                                 \n"," dense (Dense)               (None, 64)                1183808   \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1212513 (4.63 MB)\n","Trainable params: 1212513 (4.63 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# Model params\n","input_shape = (150, 150, 3)\n","num_classes = 1 # Number of outputs per input\n","\n","# Model trained on training set\n","model_our_SiF_filtered = create_cnn_model(input_shape, num_classes)\n","model_our_SiF_filtered.compile(optimizer=RMSprop(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model_our_SiF_filtered.fit(train_generator_SiF_filtered, epochs=10)\n","model_our_SiF_filtered.summary()  # Print model summary\n","\n","# Save model\n","model_dir = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Filtered.keras'\n","#if not os.path.exists(model_dir):\n","#    os.makedirs(model_dir)\n","model_our_SiF_filtered.save(model_dir)"]},{"cell_type":"markdown","metadata":{"id":"RHh3JfxXIv3b","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## Our - SiF-DeepVC - Regular"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"14ef8588-a173-4dda-dfb9-361adc39132c","id":"04uV5zPXW8Vc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","220/220 [==============================] - 2418s 11s/step - loss: 0.5861 - accuracy: 0.6734\n","Epoch 2/10\n","220/220 [==============================] - 51s 230ms/step - loss: 0.4174 - accuracy: 0.8149\n","Epoch 3/10\n","220/220 [==============================] - 51s 230ms/step - loss: 0.2840 - accuracy: 0.8873\n","Epoch 4/10\n","220/220 [==============================] - 51s 230ms/step - loss: 0.2076 - accuracy: 0.9222\n","Epoch 5/10\n","220/220 [==============================] - 51s 231ms/step - loss: 0.1831 - accuracy: 0.9326\n","Epoch 6/10\n","220/220 [==============================] - 51s 230ms/step - loss: 0.1749 - accuracy: 0.9373\n","Epoch 7/10\n","220/220 [==============================] - 51s 233ms/step - loss: 0.1560 - accuracy: 0.9451\n","Epoch 8/10\n","220/220 [==============================] - 51s 233ms/step - loss: 0.1552 - accuracy: 0.9448\n","Epoch 9/10\n","220/220 [==============================] - 50s 229ms/step - loss: 0.1433 - accuracy: 0.9471\n","Epoch 10/10\n","220/220 [==============================] - 51s 233ms/step - loss: 0.1411 - accuracy: 0.9514\n","Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_9 (Conv2D)           (None, 150, 150, 32)      896       \n","                                                                 \n"," max_pooling2d_9 (MaxPoolin  (None, 75, 75, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 73, 73, 32)        9248      \n","                                                                 \n"," max_pooling2d_10 (MaxPooli  (None, 36, 36, 32)        0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 34, 34, 64)        18496     \n","                                                                 \n"," max_pooling2d_11 (MaxPooli  (None, 17, 17, 64)        0         \n"," ng2D)                                                           \n","                                                                 \n"," flatten_3 (Flatten)         (None, 18496)             0         \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                1183808   \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1212513 (4.63 MB)\n","Trainable params: 1212513 (4.63 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# Model params\n","input_shape = (150, 150, 3)\n","num_classes = 1 # Number of outputs per input\n","\n","# Model trained on training set\n","model_our_SiF_regular = create_cnn_model(input_shape, num_classes)\n","model_our_SiF_regular.compile(optimizer=RMSprop(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model_our_SiF_regular.fit(train_generator_SiF_reg, epochs=10)\n","model_our_SiF_regular.summary()  # Print model summary\n","model_our_SiF_regular.save(root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular.keras')"]},{"cell_type":"markdown","metadata":{"id":"lPXtZH-CG4n1"},"source":["## Our - SiF-DeepVC - Regular - Dropout"]},{"cell_type":"code","source":["# Regular SiF\n","input_shape = (150, 150, 3)\n","num_classes = 1 # Number of outputs per input\n","\n","# Model trained on training set\n","sif_reg_drop = increased_dropout(input_shape, num_classes)\n","sif_reg_drop.compile(optimizer=RMSprop(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","sif_reg_drop.fit(train_generator_SiF_reg, epochs=10)\n","sif_reg_drop.summary()  # Print model summary\n","sif_reg_drop.save(root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular-Dropout.keras')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pxt7rsILG6gD","outputId":"5f2f3618-f9ac-4373-c8f2-835cbd59cd96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","220/220 [==============================] - 51s 229ms/step - loss: 0.6868 - accuracy: 0.5974\n","Epoch 2/10\n","220/220 [==============================] - 52s 234ms/step - loss: 0.5076 - accuracy: 0.7519\n","Epoch 3/10\n","220/220 [==============================] - 50s 229ms/step - loss: 0.4192 - accuracy: 0.8178\n","Epoch 4/10\n","220/220 [==============================] - 51s 232ms/step - loss: 0.3207 - accuracy: 0.8670\n","Epoch 5/10\n","220/220 [==============================] - 50s 228ms/step - loss: 0.2689 - accuracy: 0.8973\n","Epoch 6/10\n","220/220 [==============================] - 50s 229ms/step - loss: 0.2401 - accuracy: 0.9098\n","Epoch 7/10\n","220/220 [==============================] - 50s 228ms/step - loss: 0.2294 - accuracy: 0.9141\n","Epoch 8/10\n","220/220 [==============================] - 50s 228ms/step - loss: 0.2221 - accuracy: 0.9186\n","Epoch 9/10\n","220/220 [==============================] - 50s 229ms/step - loss: 0.2135 - accuracy: 0.9228\n","Epoch 10/10\n","220/220 [==============================] - 51s 230ms/step - loss: 0.2165 - accuracy: 0.9209\n","Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_15 (Conv2D)          (None, 150, 150, 64)      1792      \n","                                                                 \n"," max_pooling2d_15 (MaxPooli  (None, 75, 75, 64)        0         \n"," ng2D)                                                           \n","                                                                 \n"," dropout_8 (Dropout)         (None, 75, 75, 64)        0         \n","                                                                 \n"," conv2d_16 (Conv2D)          (None, 73, 73, 64)        36928     \n","                                                                 \n"," max_pooling2d_16 (MaxPooli  (None, 36, 36, 64)        0         \n"," ng2D)                                                           \n","                                                                 \n"," dropout_9 (Dropout)         (None, 36, 36, 64)        0         \n","                                                                 \n"," conv2d_17 (Conv2D)          (None, 34, 34, 128)       73856     \n","                                                                 \n"," max_pooling2d_17 (MaxPooli  (None, 17, 17, 128)       0         \n"," ng2D)                                                           \n","                                                                 \n"," dropout_10 (Dropout)        (None, 17, 17, 128)       0         \n","                                                                 \n"," flatten_5 (Flatten)         (None, 36992)             0         \n","                                                                 \n"," dense_10 (Dense)            (None, 128)               4735104   \n","                                                                 \n"," dropout_11 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_11 (Dense)            (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 4847809 (18.49 MB)\n","Trainable params: 4847809 (18.49 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"rgeyLRvlLgSI"},"source":["## Our - SiF-DeepVC - Regular - Deep"]},{"cell_type":"code","source":["# SiF Regular\n","input_shape = (150, 150, 3)\n","num_classes = 1 # Number of outputs per input\n","\n","# Model trained on training set\n","sif_reg_deep = deeper_model(input_shape, num_classes)\n","sif_reg_deep.compile(optimizer=RMSprop(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","sif_reg_deep.fit(train_generator_SiF_reg, epochs=10)\n","sif_reg_deep.summary()  # Print model summary\n","sif_reg_deep.save(root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular-Deep.keras')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d24077b6-79d6-4c51-b53b-49948fe665ad","id":"oQ6VC6JNLgSV"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","220/220 [==============================] - 53s 232ms/step - loss: 0.6757 - accuracy: 0.5450\n","Epoch 2/10\n","220/220 [==============================] - 51s 232ms/step - loss: 0.4138 - accuracy: 0.8102\n","Epoch 3/10\n","220/220 [==============================] - 51s 233ms/step - loss: 0.2569 - accuracy: 0.9018\n","Epoch 4/10\n","220/220 [==============================] - 51s 232ms/step - loss: 0.2149 - accuracy: 0.9223\n","Epoch 5/10\n","220/220 [==============================] - 51s 231ms/step - loss: 0.1892 - accuracy: 0.9329\n","Epoch 6/10\n","220/220 [==============================] - 52s 235ms/step - loss: 0.1870 - accuracy: 0.9331\n","Epoch 7/10\n","220/220 [==============================] - 51s 232ms/step - loss: 0.1745 - accuracy: 0.9370\n","Epoch 8/10\n","220/220 [==============================] - 53s 239ms/step - loss: 0.1742 - accuracy: 0.9400\n","Epoch 9/10\n","220/220 [==============================] - 51s 230ms/step - loss: 0.1651 - accuracy: 0.9417\n","Epoch 10/10\n","220/220 [==============================] - 51s 232ms/step - loss: 0.1569 - accuracy: 0.9422\n","Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_42 (Conv2D)          (None, 150, 150, 32)      896       \n","                                                                 \n"," conv2d_43 (Conv2D)          (None, 148, 148, 32)      9248      \n","                                                                 \n"," max_pooling2d_30 (MaxPooli  (None, 74, 74, 32)        0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_44 (Conv2D)          (None, 74, 74, 64)        18496     \n","                                                                 \n"," conv2d_45 (Conv2D)          (None, 72, 72, 64)        36928     \n","                                                                 \n"," max_pooling2d_31 (MaxPooli  (None, 36, 36, 64)        0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_46 (Conv2D)          (None, 36, 36, 128)       73856     \n","                                                                 \n"," conv2d_47 (Conv2D)          (None, 34, 34, 128)       147584    \n","                                                                 \n"," max_pooling2d_32 (MaxPooli  (None, 17, 17, 128)       0         \n"," ng2D)                                                           \n","                                                                 \n"," flatten_10 (Flatten)        (None, 36992)             0         \n","                                                                 \n"," dense_20 (Dense)            (None, 256)               9470208   \n","                                                                 \n"," dropout_25 (Dropout)        (None, 256)               0         \n","                                                                 \n"," dense_21 (Dense)            (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 9757473 (37.22 MB)\n","Trainable params: 9757473 (37.22 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Our - H-Voice + SiF-DeepVC - Regular"],"metadata":{"id":"voBmG2uow6kP"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGTDK_RjItT_","outputId":"35407dd1-af26-44e1-d7c4-7521879652cf","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","260/260 [==============================] - 988s 4s/step - loss: 0.4973 - accuracy: 0.7266\n","Epoch 2/10\n","260/260 [==============================] - 60s 229ms/step - loss: 0.3787 - accuracy: 0.7989\n","Epoch 3/10\n","260/260 [==============================] - 59s 227ms/step - loss: 0.2936 - accuracy: 0.8660\n","Epoch 4/10\n","260/260 [==============================] - 59s 226ms/step - loss: 0.2118 - accuracy: 0.9120\n","Epoch 5/10\n","260/260 [==============================] - 60s 230ms/step - loss: 0.1650 - accuracy: 0.9417\n","Epoch 6/10\n","260/260 [==============================] - 60s 231ms/step - loss: 0.1404 - accuracy: 0.9511\n","Epoch 7/10\n","260/260 [==============================] - 60s 231ms/step - loss: 0.1216 - accuracy: 0.9569\n","Epoch 8/10\n","260/260 [==============================] - 59s 227ms/step - loss: 0.1187 - accuracy: 0.9625\n","Epoch 9/10\n","260/260 [==============================] - 59s 228ms/step - loss: 0.1150 - accuracy: 0.9606\n","Epoch 10/10\n","260/260 [==============================] - 59s 228ms/step - loss: 0.1073 - accuracy: 0.9646\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 150, 150, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 75, 75, 32)        0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 73, 73, 32)        9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 36, 36, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 17, 17, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 18496)             0         \n","                                                                 \n"," dense (Dense)               (None, 64)                1183808   \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1212513 (4.63 MB)\n","Trainable params: 1212513 (4.63 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# Model params\n","input_shape = (150, 150, 3)\n","num_classes = 1 # Number of outputs per input\n","\n","# Model trained on training set\n","model_our_HVoice_SiF_regular = create_cnn_model(input_shape, num_classes)\n","model_our_HVoice_SiF_regular.compile(optimizer=RMSprop(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model_our_HVoice_SiF_regular.fit(train_generator_HVoice_SiF_Reg, epochs=10)\n","model_our_HVoice_SiF_regular.summary()  # Print model summary\n","\n","# Save model\n","model_dir = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice_SiF-Regular.keras'\n","#if not os.path.exists(model_dir):\n","#    os.makedirs(model_dir)\n","model_our_HVoice_SiF_regular.save(model_dir)"]},{"cell_type":"markdown","source":["## Our - H-Voice + SiF-DeepVC - Filtered"],"metadata":{"id":"93SySYw8xFXv"}},{"cell_type":"code","source":["# Model params\n","input_shape = (150, 150, 3)\n","num_classes = 1 # Number of outputs per input\n","\n","# Model trained on training set\n","model_our_HVoice_SiF_filtered = create_cnn_model(input_shape, num_classes)\n","model_our_HVoice_SiF_filtered.compile(optimizer=RMSprop(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model_our_HVoice_SiF_filtered.fit(train_generator_HVoice_SiF_Filtered, epochs=10)\n","model_our_HVoice_SiF_filtered.summary()  # Print model summary\n","\n","# Save model\n","model_dir = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice_SiF-Filtered.keras'\n","#if not os.path.exists(model_dir):\n","#    os.makedirs(model_dir)\n","model_our_HVoice_SiF_filtered.save(model_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3T3jtb_xLoM","outputId":"040c02f6-dcae-4610-ca29-670fdba3a6a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","262/262 [==============================] - 3521s 13s/step - loss: 0.4838 - accuracy: 0.7370\n","Epoch 2/10\n","262/262 [==============================] - 51s 193ms/step - loss: 0.3173 - accuracy: 0.8520\n","Epoch 3/10\n","262/262 [==============================] - 50s 190ms/step - loss: 0.2001 - accuracy: 0.9239\n","Epoch 4/10\n","262/262 [==============================] - 50s 190ms/step - loss: 0.1516 - accuracy: 0.9476\n","Epoch 5/10\n","262/262 [==============================] - 50s 191ms/step - loss: 0.1274 - accuracy: 0.9588\n","Epoch 6/10\n","262/262 [==============================] - 50s 191ms/step - loss: 0.1140 - accuracy: 0.9625\n","Epoch 7/10\n","262/262 [==============================] - 50s 190ms/step - loss: 0.1056 - accuracy: 0.9654\n","Epoch 8/10\n","262/262 [==============================] - 49s 188ms/step - loss: 0.1008 - accuracy: 0.9666\n","Epoch 9/10\n","262/262 [==============================] - 50s 189ms/step - loss: 0.0941 - accuracy: 0.9696\n","Epoch 10/10\n","262/262 [==============================] - 50s 192ms/step - loss: 0.0909 - accuracy: 0.9716\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 150, 150, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 75, 75, 32)        0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 73, 73, 32)        9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 36, 36, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 17, 17, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 18496)             0         \n","                                                                 \n"," dense (Dense)               (None, 64)                1183808   \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1212513 (4.63 MB)\n","Trainable params: 1212513 (4.63 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"QAkKHdrcUTKb"},"source":["# Performances"]},{"cell_type":"markdown","metadata":{"id":"diZ5MJ91IXaL","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## Data - SiF-DeepVC - Regular"]},{"cell_type":"markdown","metadata":{"id":"uK7d1mxgwKZd","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["### Original-HVoice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyUwVhnpGXoh"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","# Load the model on CPU\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Original-HVoice.keras'\n","model_original_HVoice = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9A02p3L84r1u","outputId":"dc9340d8-8940-47b9-d5cb-b85fee08531e"},"outputs":[{"name":"stdout","output_type":"stream","text":["43/43 [==============================] - 9s 200ms/step - loss: 9.8169 - tp: 663.0000 - fp: 624.0000 - tn: 47.0000 - fn: 16.0000 - accuracy: 0.5259 - precision: 0.5152 - recall: 0.9764 - auc: 0.5428\n","Validation accuracy: 52.59259343147278%\n"]}],"source":["# Validation Set\n","evaluation_results = model_original_HVoice.evaluate(valid_generator_SiF_reg)\n","print(f'Validation accuracy: {evaluation_results[5] * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-QgZuVF4uXX","outputId":"30d48f27-6d15-4f87-a4eb-98df2e254dfc"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 223ms/step - loss: 9.9456 - tp: 672.0000 - fp: 611.0000 - tn: 54.0000 - fn: 13.0000 - accuracy: 0.5378 - precision: 0.5238 - recall: 0.9810 - auc: 0.5567\n","Test accuracy: 53.77777814865112%\n","FPR: 52.37724084177708%\n"]}],"source":["# Test set\n","evaluation_results = model_original_HVoice.evaluate(test_generator_SiF_reg)\n","print(f'Test accuracy: {evaluation_results[5] * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPfKefSzwX7c","outputId":"368f3414-d0d2-4a3d-dc82-54b4d90638b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 224ms/step - loss: 19.3696 - tp: 0.0000e+00 - fp: 910.0000 - tn: 90.0000 - fn: 0.0000e+00 - accuracy: 0.0900 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00\n","Target Test accuracy: 9.000000357627869%\n","TPR: 17.710234653885813%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","evaluation_results = model_original_HVoice.evaluate(deep4s_generator_SiF_reg)\n","print(f'Target Test accuracy: {evaluation_results[5] * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_original_HVoice.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjEnjwsGjlNK","outputId":"cb6cae18-155f-4dd0-92e3-0c2dec880cae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 224ms/step\n","FPR: 94.58646616541353%\n"]}]},{"cell_type":"markdown","metadata":{"id":"RCb7Y8PwwG-q","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["### Our-HVoice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hu8WUAW0GXoh"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice.keras'\n","model_our_HVoice = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcXhpXJZGXoh","outputId":"c41f3414-4f23-4047-e074-520e3d47bd72"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/jupyter-shl224/.local/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - accuracy: 0.5279 - loss: 2.9056\n","Validation accuracy: 52.37036943435669%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice.evaluate(valid_generator_SiF_reg)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E1we3R5cGXoi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a185210a-aaab-41d6-918c-d2cc398d2ee1"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 228ms/step - loss: 3.6510 - accuracy: 0.5074\n","Test accuracy: 50.740742683410645%\n","FPR: 0.0%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice.evaluate(test_generator_SiF_reg)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GqzQyCnGXoi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e4fdde3-3d7e-46fb-f8f8-5abff9d1c99f"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 218ms/step - loss: 7.3188 - accuracy: 0.0000e+00\n","Target Test accuracy: 0.0%\n","TPR: 17.710234653885813%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_HVoice.evaluate(deep4s_generator_SiF_reg)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"id":"glfAhQe8kYu_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5c0087c2-2001-4c54-e9b7-c6266259028c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 221ms/step\n","FPR: 100.0%\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"7EAw8uU2HZo9"},"source":["### Our-HVoice-Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvgNT_jUHZpJ"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice-Dropout.keras'\n","model_our_HVoice_Dropout = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"4f19b8e9-e363-4cd4-f48c-65b6628d8c78","colab":{"base_uri":"https://localhost:8080/"},"id":"00ys8-PuHZpJ"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 230ms/step - loss: 2.3661 - accuracy: 0.4996\n","Validation accuracy: 49.96315538883209%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice_Dropout.evaluate(valid_generator_SiF_reg)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RNBSIkLHZpK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4bc3891e-a4c5-4ce6-e35b-afda2ed29451"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 228ms/step - loss: 2.3670 - accuracy: 0.5074\n","Test accuracy: 50.740742683410645%\n","FPR: 0.0%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice_Dropout.evaluate(test_generator_SiF_reg)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QOsPh_qHZpK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"da95010f-3b2f-4a60-aef4-9f38db951160"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 231ms/step - loss: 4.6992 - accuracy: 0.0000e+00\n","Target Test accuracy: 0.0%\n","TPR: 17.710234653885813%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_HVoice_Dropout.evaluate(deep4s_generator_SiF_reg)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice_Dropout.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"id":"U5Vf-dEnk6uP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"65d12a16-3a51-42d3-ad3b-fbbbe619b8ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 226ms/step\n","FPR: 100.0%\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"tHytz4CBL00Y"},"source":["### Our-HVoice-Deep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tt8pv30mL00i"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice-Deep.keras'\n","model_our_HVoice_Deep = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"98df2adc-5fc7-4d90-f321-e865d6856f5c","colab":{"base_uri":"https://localhost:8080/"},"id":"3vY-CSlvL00i"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 227ms/step - loss: 0.6933 - accuracy: 0.4996\n","Validation accuracy: 49.96315538883209%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice_Deep.evaluate(valid_generator_SiF_reg)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"04bc81d8-af66-4f0f-b1e3-5b1a2451365a","colab":{"base_uri":"https://localhost:8080/"},"id":"ADZHqWHhL00j"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 227ms/step - loss: 0.6936 - accuracy: 0.4926\n","Test accuracy: 49.259260296821594%\n","FPR: 52.37724084177708%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice_Deep.evaluate(test_generator_SiF_reg)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"769d947c-dafc-48cb-8b71-bb585a48b242","colab":{"base_uri":"https://localhost:8080/"},"id":"g4AaTdbxL00j"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 216ms/step - loss: 0.6754 - accuracy: 1.0000\n","Target Test accuracy: 100.0%\n","TPR: 15.553248617592082%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_HVoice_Deep.evaluate(deep4s_generator_SiF_reg)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice_Deep.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"id":"073NgeeFp0Xe","outputId":"578a1cce-3e8c-49a8-b825-1cb891c714cb","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 222ms/step\n","FPR: 0.0%\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"wl86mtOmGXoi"},"source":["### Our-SiF-Regular"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t2UXXWMmGXoi"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular.keras'\n","model_our_SiF_regular = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ay7IPOfvIaWn","outputId":"2dfb7586-d879-4590-f1ae-0ea4f760e76f"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 223ms/step - loss: 0.2032 - accuracy: 0.9263\n","Validation accuracy: 92.63080358505249%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_SiF_regular.evaluate(valid_generator_SiF_reg)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yi1ZZ6RpK8iP","outputId":"4368b1c7-d59c-45bc-c909-e0fd25432aba"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 223ms/step - loss: 0.1918 - accuracy: 0.9385\n","Test accuracy: 93.85185241699219%\n","FPR: 0.0%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_SiF_regular.evaluate(test_generator_SiF_reg)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-d17ZdNVSlBm","outputId":"56ca8a8e-f163-4930-f9f2-5250fc49af19","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 216ms/step - loss: 0.1947 - accuracy: 0.9400\n","Target Test accuracy: 93.99999976158142%\n","TPR: 17.71022891352432%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_SiF_regular.evaluate(deep4s_generator_SiF_reg)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_SiF_regular.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-yTARwYqlf-","outputId":"0880e233-1edb-48d0-d2d9-8dba7a8061d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 225ms/step\n","FPR: 53.0827067669173%\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"SwbcwwDFIwO-"},"source":["### Our-SiF-Regular-Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWuw0PmEIwPJ"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular-Dropout.keras'\n","model_our_SiF_regular_Dropout = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b42648f-97e6-464d-dc23-f16eaae2406c","id":"4rt2DuHXIwPJ"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 227ms/step - loss: 0.1927 - accuracy: 0.9344\n","Validation accuracy: 93.44141483306885%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_SiF_regular_Dropout.evaluate(valid_generator_SiF_reg)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d66f3396-993b-4c57-be10-d89c4c11e613","id":"UPzLC18nIwPJ"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 225ms/step - loss: 0.1849 - accuracy: 0.9348\n","Test accuracy: 93.48148107528687%\n","FPR: 0.0%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_SiF_regular_Dropout.evaluate(test_generator_SiF_reg)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"65cde215-4924-430d-aee1-8a308a2a442d","tags":[],"id":"1336n1zFIwPK"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 221ms/step - loss: 0.1757 - accuracy: 0.9480\n","Target Test accuracy: 94.80000138282776%\n","TPR: 17.71022891352432%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_SiF_regular_Dropout.evaluate(deep4s_generator_SiF_reg)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_SiF_regular_Dropout.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1gjLOxdoq-f1","outputId":"15dd74f9-c511-4f0e-a364-e5c555a9b217"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 223ms/step\n","FPR: 52.03007518796993%\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"gvplpdqjMDKc"},"source":["### Our-SiF-Regular-Deep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sMJs0e7yMDKr"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular-Deep.keras'\n","model_our_SiF_regular_Deep = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"504b635e-7166-41ba-8b76-bca3c67043a3","id":"l-FonulSMDKs"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 220ms/step - loss: 0.2035 - accuracy: 0.9226\n","Validation accuracy: 92.26234555244446%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_SiF_regular_Deep.evaluate(valid_generator_SiF_reg)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"10a11456-5cbb-4e96-979a-d0752d4080c3","id":"YaqrHHYxMDKs"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 221ms/step - loss: 0.1693 - accuracy: 0.9393\n","Test accuracy: 93.92592310905457%\n","FPR: 0.0%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_SiF_regular_Deep.evaluate(test_generator_SiF_reg)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"44b03eb8-6daa-41bb-c0b9-6a456e462326","tags":[],"id":"3jkV6ROeMDKs"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 218ms/step - loss: 0.0891 - accuracy: 0.9830\n","Target Test accuracy: 98.29999804496765%\n","TPR: 17.710234653885813%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_SiF_regular_Deep.evaluate(deep4s_generator_SiF_reg)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_SiF_regular_Deep.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QqtPN8ujrKWB","outputId":"7137ef7a-32ef-4cde-f16a-5a13018f3ab4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 219ms/step\n","FPR: 48.87218045112782%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"f4NjIFYsGXon"},"source":["### Our-SiF-Filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SjPVCq7CGXon"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Filtered.keras'\n","model_our_SiF_filtered = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDJvTgMDGXon","outputId":"401c1c62-5eab-46a3-91dd-3abeaf686d7e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 498s 12s/step - loss: 0.9362 - accuracy: 0.6559\n","Validation accuracy: 65.58585166931152%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_SiF_filtered.evaluate(valid_generator_SiF_reg)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_5UgJC1GXon","outputId":"34daa710-0eaa-42ab-82ef-ce8f33e7ef1a","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 225ms/step - loss: 0.9675 - accuracy: 0.6452\n","Test accuracy: 64.51851725578308%\n","FPR: 0.0%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_SiF_filtered.evaluate(test_generator_SiF_reg)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNLb2nNTGXon","outputId":"19b1e226-cc01-4847-eafd-3931f1b1884d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 221ms/step - loss: 0.9017 - accuracy: 0.6240\n","Target Test accuracy: 62.40000128746033%\n","TPR: 15.553246098742523%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_SiF_filtered.evaluate(deep4s_generator_SiF_reg)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_SiF_filtered.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWpihZxgripy","outputId":"18e4c91d-ba47-4001-bf0e-c1006e077689"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 226ms/step\n","FPR: 54.88721804511278%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"aHfJEvjJHyoA"},"source":["### Our-HVoice_SiF-Regular"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xnKV9fKoHyof"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice_SiF-Regular.keras'\n","model_our_HVoice_SiF_Regular = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"e88227e4-a8de-4ca1-d66d-421440d34501","id":"zLew1oYQHyof","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 226ms/step - loss: 2.7234 - accuracy: 0.5357\n","Validation accuracy: 53.57406139373779%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice_SiF_Regular.evaluate(valid_generator_SiF_reg)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"fe64e1d5-93c9-47a9-df93-0b2d7ddcb6b3","id":"GyPKF0Y4Hyog","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 225ms/step - loss: 2.7251 - accuracy: 0.5311\n","Test accuracy: 53.111112117767334%\n","FPR: 52.37724084177708%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice_SiF_Regular.evaluate(test_generator_SiF_reg)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"f7024918-a036-4c5b-e01a-7f237333d753","id":"mMkHHNrqHyog","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 226ms/step - loss: 0.0300 - accuracy: 0.9930\n","Target Test accuracy: 99.29999709129333%\n","TPR: 15.553246098742523%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_HVoice_SiF_Regular.evaluate(deep4s_generator_SiF_reg)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice_SiF_Regular.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ortsrxMrt7f","outputId":"f1f638b6-144e-438f-8d3c-95ffe4a318e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 222ms/step\n","FPR: 4.661654135338346%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"TIfqqA5HIU7S"},"source":["### Our-HVoice_SiF-Filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"753W20BcIU7Z"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice_SiF-Filtered'\n","model_our_HVoice_SiF_Filtered = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"21fdd872-bd0d-467a-8616-a9adc905bb04","id":"wOAySkwxIU7Z","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 226ms/step - loss: 1.7844 - accuracy: 0.5578\n","Validation accuracy: 55.78482151031494%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice_SiF_Filtered.evaluate(valid_generator_SiF_reg)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"5d720c84-cfc5-4049-fbe3-5e44ac60eb5b","id":"ydZslQdYIU7a","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 226ms/step - loss: 1.8394 - accuracy: 0.5600\n","Test accuracy: 56.00000023841858%\n","FPR: 52.37724084177708%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice_SiF_Filtered.evaluate(test_generator_SiF_reg)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"c3d336e8-6162-40cb-d9b8-701e85dcea56","id":"0K9RSBPDIU7a","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 226ms/step - loss: 0.0376 - accuracy: 0.9900\n","Target Test accuracy: 99.00000095367432%\n","TPR: 15.553246098742523%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_HVoice_SiF_Filtered.evaluate(deep4s_generator_SiF_reg)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice_SiF_Filtered.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f87mucP5r8b9","outputId":"9cf9239f-92c7-40d6-97fd-144fb2164696"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 224ms/step\n","FPR: 7.218045112781955%\n"]}]},{"cell_type":"markdown","metadata":{"id":"VFhskoX4UjQW","tags":[]},"source":["## Data - SiF-DeepVC - Filtered\n"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"wuaOu1FRGXoo"},"source":["### Original-HVoice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cqYFavrcGXoo"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","# Load the model on CPU\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Original-HVoice.keras'\n","model_original_HVoice = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2RlsPO6GXoo","outputId":"078326d5-4fae-41a3-a42b-f9fcc19d433f"},"outputs":[{"name":"stdout","output_type":"stream","text":["43/43 [==============================] - 10s 227ms/step - loss: 7.5273 - tp: 686.0000 - fp: 607.0000 - tn: 44.0000 - fn: 14.0000 - accuracy: 0.5403 - precision: 0.5305 - recall: 0.9800 - auc: 0.5480\n","Validation accuracy: 54.034048318862915%\n"]}],"source":["# Validation Set\n","evaluation_results = model_original_HVoice.evaluate(valid_generator_SiF_filtered)\n","print(f'Validation accuracy: {evaluation_results[5] * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDzKCP3YGXoo","outputId":"905f0708-a27b-4097-db91-044109c61e16","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 225ms/step - loss: 8.0180 - tp: 645.0000 - fp: 650.0000 - tn: 44.0000 - fn: 11.0000 - accuracy: 0.5104 - precision: 0.4981 - recall: 0.9832 - auc: 0.5437\n","Test accuracy: 51.03703737258911%\n","FPR: 49.80694980694981%\n"]}],"source":["# Test set\n","evaluation_results = model_original_HVoice.evaluate(test_generator_SiF_filtered)\n","print(f'Test accuracy: {evaluation_results[5] * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N54hvfHMGXoo","outputId":"60ef4fab-a0e6-4f90-af38-1e6bcc104928","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 225ms/step - loss: 15.6108 - tp: 0.0000e+00 - fp: 943.0000 - tn: 57.0000 - fn: 0.0000e+00 - accuracy: 0.0570 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00\n","Target Test accuracy: 5.700000002980232%\n","TPR: 21.49927159173076%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","evaluation_results = model_original_HVoice.evaluate(deep4s_generator_SiF_filtered)\n","print(f'Target Test accuracy: {evaluation_results[5] * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_original_HVoice.predict(test_generator_SiF_filtered) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_filtered.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ygeKQcyEsHOa","outputId":"3c815126-78f4-4069-a70e-7241e5740405"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 226ms/step\n","FPR: 96.39769452449568%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"5YYGtkcwGXoo"},"source":["### Our-HVoice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awOX_JcBGXop"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice.keras'\n","model_our_HVoice = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ut6QRszYGXop","colab":{"base_uri":"https://localhost:8080/"},"outputId":"11e78248-9d72-4750-8ff9-8354eeab2739"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 499s 12s/step - loss: 3.1224 - accuracy: 0.5181\n","Validation accuracy: 51.81347131729126%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice.evaluate(valid_generator_SiF_filtered)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BaJMR4M6GXop","outputId":"1e08c6f2-f7d1-4ce3-e5ac-259209f3139e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 222ms/step - loss: 3.3557 - accuracy: 0.4852\n","Test accuracy: 48.51851761341095%\n","FPR: 0.0%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice.evaluate(test_generator_SiF_filtered)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Je4t8rdjGXop","outputId":"55bd9788-2126-481f-c176-94e4a340b04b","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 222ms/step - loss: 6.5305 - accuracy: 0.0010\n","Target Test accuracy: 0.10000000474974513%\n","TPR: 21.49927159173076%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_HVoice.evaluate(deep4s_generator_SiF_filtered)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice.predict(test_generator_SiF_filtered) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_filtered.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kAzLJYezsUs5","outputId":"3a6e1c7c-8a97-4baa-944f-06d1d32fb779"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 228ms/step\n","FPR: 99.85590778097982%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"AR9CVmGXJBM-"},"source":["### Our-HVoice-Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQ8nTDRSJBNI"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice-Dropout.keras'\n","model_our_HVoice_Dropout = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"428a6828-1e19-4951-82b1-c1171beb19df","id":"PFdycoRwJBNI"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 221ms/step - loss: 1.8623 - accuracy: 0.5174\n","Validation accuracy: 51.73945426940918%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice_Dropout.evaluate(valid_generator_SiF_filtered)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"3bc01072-70f1-440b-9b42-4abf68f047cf","colab":{"base_uri":"https://localhost:8080/"},"id":"HEMJ-Bz3JBNI"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 223ms/step - loss: 1.9934 - accuracy: 0.4859\n","Test accuracy: 48.592591285705566%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice_Dropout.evaluate(test_generator_SiF_filtered)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"3dd55dba-52b1-4bd8-ae79-d7463aa96dca","colab":{"base_uri":"https://localhost:8080/"},"id":"yTTW8xTIJBNI"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 217ms/step - loss: 3.8112 - accuracy: 0.0000e+00\n","Target Test accuracy: 0.0%\n","TPR: 0.01869522635567301%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_HVoice_Dropout.evaluate(deep4s_generator_SiF_filtered)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice_Dropout.predict(test_generator_SiF_filtered) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_filtered.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLV-HYpEtMeY","outputId":"c6d1692a-7e08-4c1e-a7bc-afa932b538a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 9s 219ms/step\n","FPR: 100.0%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"VCNAcnJmMfnw"},"source":["### Our-HVoice-Deep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G1QbGEU3Mfn6"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice-Deep.keras'\n","model_our_HVoice_Deep = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5630ee6b-442c-4a78-ecdc-a059e2d16af0","id":"4f8OG0BvMfn6"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 227ms/step - loss: 0.6940 - accuracy: 0.4819\n","Validation accuracy: 48.18652868270874%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice_Deep.evaluate(valid_generator_SiF_filtered)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"5d761d34-3dda-4ef4-dee0-e142d0473a9c","colab":{"base_uri":"https://localhost:8080/"},"id":"PxLDD0o1Mfn6"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 220ms/step - loss: 0.6928 - accuracy: 0.5141\n","Test accuracy: 51.407408714294434%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice_Deep.evaluate(test_generator_SiF_filtered)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"418060e9-db1c-4c67-f9df-25dc82268112","colab":{"base_uri":"https://localhost:8080/"},"id":"Kvmn-2mwMfn6"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 222ms/step - loss: 0.6781 - accuracy: 1.0000\n","Target Test accuracy: 100.0%\n","TPR: 17.710234653885813%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_HVoice_Deep.evaluate(deep4s_generator_SiF_filtered)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice_Deep.predict(test_generator_SiF_filtered) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_filtered.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZ6jg9bntQSH","outputId":"5bec99d7-6362-49ee-dec8-977eafef846b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 221ms/step\n","FPR: 0.0%\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"YD_vv_nLCfuZ"},"source":["### Our-SiF-Regular"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i3zho6_UCfu1"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular.keras'\n","model_our_SiF_regular = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"69fd8bf8-fdbd-48f8-f437-60bac44b6268","id":"uMgDX3EzCfu2"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 220ms/step - loss: 2.7175 - accuracy: 0.5403\n","Validation accuracy: 54.034048318862915%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_SiF_regular.evaluate(valid_generator_SiF_filtered)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3740733a-3a80-4596-b912-dd7c2cedc0ca","id":"yD9M8bF8Cfu2"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 222ms/step - loss: 2.9138 - accuracy: 0.5074\n","Test accuracy: 50.740742683410645%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_SiF_regular.evaluate(test_generator_SiF_filtered)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"149db4ab-29e4-4af1-c077-ee2fa6caa2bf","tags":[],"id":"ne2-UGvPCfu2"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 225ms/step - loss: 5.3238 - accuracy: 0.1130\n","Target Test accuracy: 11.299999803304672%\n","TPR: 0.01869522635567301%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_SiF_regular.evaluate(deep4s_generator_SiF_filtered)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_SiF_regular.predict(test_generator_SiF_filtered) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_filtered.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1w_F09utgMB","outputId":"ab1f8d20-aa6c-49e6-8403-37005a343058"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 9s 220ms/step\n","FPR: 90.05763688760807%\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"5CGVDJ5aJI9G"},"source":["### Our-SiF-Regular-Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QT_uEP6bJI9Q"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular-Dropout.keras'\n","model_our_SiF_regular_Dropout = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"61500a4d-aeab-48d0-ef64-56038454d662","id":"9g5XAKOGJI9Q"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 218ms/step - loss: 2.2934 - accuracy: 0.5574\n","Validation accuracy: 55.736494064331055%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_SiF_regular_Dropout.evaluate(valid_generator_SiF_filtered)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a51ae23f-9f98-4438-9bcf-4c213b5be1b0","id":"QWoF29VsJI9R"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 233ms/step - loss: 2.4375 - accuracy: 0.5296\n","Test accuracy: 52.9629647731781%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_SiF_regular_Dropout.evaluate(test_generator_SiF_filtered)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6a5a2360-3843-4ed4-cf2d-e67c590e248c","tags":[],"id":"fQQziPstJI9R"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 220ms/step - loss: 4.7363 - accuracy: 0.0840\n","Target Test accuracy: 8.399999886751175%\n","TPR: 0.01869522635567301%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_SiF_regular_Dropout.evaluate(deep4s_generator_SiF_filtered)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_SiF_regular_Dropout.predict(test_generator_SiF_filtered) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_filtered.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mhy_A20Jtp41","outputId":"4ff1d840-497d-44be-9a24-19fc50088634"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 227ms/step\n","FPR: 93.65994236311239%\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"JVth1xbEM3_H"},"source":["### Our-SiF-Regular-Deep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1mucbuxNM3_S"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular-Deep.keras'\n","model_our_SiF_regular_Deep = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c80bf97-e792-4e27-b076-ad563dd6b265","id":"4fZFbdjSM3_S"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 220ms/step - loss: 1.8549 - accuracy: 0.5315\n","Validation accuracy: 53.145819902420044%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_SiF_regular_Deep.evaluate(valid_generator_SiF_filtered)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bef52f2c-542d-4757-eecc-575f3c81fa72","id":"r9n7NLiRM3_T"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 222ms/step - loss: 1.9270 - accuracy: 0.5015\n","Test accuracy: 50.14814734458923%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_SiF_regular_Deep.evaluate(test_generator_SiF_filtered)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a7b4af94-cb57-4931-f65b-bb8c53a4a421","tags":[],"id":"0ATledi0M3_T"},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 226ms/step - loss: 3.4958 - accuracy: 0.1400\n","Target Test accuracy: 14.000000059604645%\n","TPR: 0.01869522635567301%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_SiF_regular_Deep.evaluate(deep4s_generator_SiF_filtered)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_SiF_regular_Deep.predict(test_generator_SiF_filtered) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_filtered.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgqbuR4wtyIf","outputId":"640dae6f-9075-415f-bfb2-18023b5dfd85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 224ms/step\n","FPR: 91.35446685878964%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"vumLB2zWCsJy"},"source":["### Our-SiF-Filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7Y9qzVZCsJz"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Filtered.keras'\n","model_our_SiF_filtered = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"6c7c1d99-fa57-4894-b501-c2f8bd9f65fd","id":"tNceA-jpCsJz","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 226ms/step - loss: 0.2126 - accuracy: 0.9289\n","Validation accuracy: 92.8941547870636%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_SiF_filtered.evaluate(valid_generator_SiF_filtered)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"251c9495-4d07-4cc2-d142-0a40d0d9eabd","id":"J6y4bl14CsJ0","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 226ms/step - loss: 0.1525 - accuracy: 0.9444\n","Test accuracy: 94.44444179534912%\n","FPR: 0.0%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_SiF_filtered.evaluate(test_generator_SiF_filtered)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"c4eb7abf-f5af-499d-980e-b52b53ef3bef","id":"R41zSAxKCsJ0","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 223ms/step - loss: 0.0602 - accuracy: 0.9830\n","Target Test accuracy: 98.29999804496765%\n","TPR: 21.49927159173076%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_SiF_filtered.evaluate(deep4s_generator_SiF_filtered)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_SiF_filtered.predict(test_generator_SiF_filtered) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_filtered.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uWurVpejt8qp","outputId":"061945a3-9528-48e7-b2c0-b83ff36b6b0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 222ms/step\n","FPR: 44.95677233429395%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"e9DzEm7jI07Y"},"source":["### Our-HVoice_SiF-Regular"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lI5RIkyI070"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice_SiF-Regular.keras'\n","model_our_HVoice_SiF_Regular = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"d5fc48bb-5055-438b-c117-36e5ceb499fb","id":"Grt8YmbxI071","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 225ms/step - loss: 1.9556 - accuracy: 0.6321\n","Validation accuracy: 63.21243643760681%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice_SiF_Regular.evaluate(valid_generator_SiF_filtered)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"2ca2a165-2cd9-454a-b9dc-91630639da5e","id":"stAzXoAhI071","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 223ms/step - loss: 1.7311 - accuracy: 0.6733\n","Test accuracy: 67.33333468437195%\n","FPR: 0.0%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice_SiF_Regular.evaluate(test_generator_SiF_filtered)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"4da526cb-11a9-4ef3-ffc8-caaf5aa353ca","id":"3bbfqy6KI071","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 217ms/step - loss: 0.2567 - accuracy: 0.9260\n","Target Test accuracy: 92.59999990463257%\n","TPR: 21.49927159173076%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_HVoice_SiF_Regular.evaluate(deep4s_generator_SiF_filtered)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice_SiF_Regular.predict(test_generator_SiF_filtered) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_filtered.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"554qNadUuJD-","outputId":"009a7891-5d21-4237-fc76-cfa98db22581"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 9s 217ms/step\n","FPR: 17.435158501440924%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"akl3VVCkI072"},"source":["### Our-HVoice_SiF-Filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzHMVRIxI072","colab":{"base_uri":"https://localhost:8080/"},"outputId":"39a47200-4174-40a2-a549-28570023da0d"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Skipping variable loading for optimizer 'RMSprop', because it has 11 variables whereas the saved optimizer has 1 variables. \n"]}],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice_SiF-Filtered.keras'\n","model_our_HVoice_SiF_Filtered = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"904ec9e4-2c5e-42aa-dab5-cea2e955008b","id":"2FVAbiQRI072","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 230ms/step - loss: 1.1553 - accuracy: 0.6603\n","Validation accuracy: 66.02516770362854%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice_SiF_Filtered.evaluate(valid_generator_SiF_filtered)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"28fb9d0e-99d1-4e34-871f-f18e5634e5ec","id":"iKXAyfxZI072","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 10s 224ms/step - loss: 1.0254 - accuracy: 0.7030\n","Test accuracy: 70.29629349708557%\n","FPR: 0.0%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice_SiF_Filtered.evaluate(test_generator_SiF_filtered)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"400c9658-b5dc-492c-b41e-da2c0057e7b4","id":"jpIqhYqyI072","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 7s 220ms/step - loss: 0.2194 - accuracy: 0.9210\n","Target Test accuracy: 92.10000038146973%\n","TPR: 21.49927159173076%\n"]}],"source":["# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n","loss_test, accuracy_test = model_our_HVoice_SiF_Filtered.evaluate(deep4s_generator_SiF_filtered)\n","print(f'Target Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute trur positive rate (TPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","TPR = TP / (TP + FN)\n","print(f'TPR: {TPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice_SiF_Filtered.predict(test_generator_SiF_filtered) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_SiF_filtered.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NanE5ohCuRV2","outputId":"b67412e6-1c0a-4c72-8085-c4ca30da85e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 9s 220ms/step\n","FPR: 23.19884726224784%\n"]}]},{"cell_type":"markdown","metadata":{"id":"j7HBl20xTRwg","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## Data - H-Voice"]},{"cell_type":"markdown","metadata":{"id":"qsg-tPW2V4KC","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["### Original-HVoice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3XpsMboZkB-"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","# Load the model on CPU\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Original-HVoice.keras'\n","model_original_HVoice = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"ggJII6qvZdw5","outputId":"8db143c4-1c81-42ff-8b55-86b06869be22"},"outputs":[{"name":"stdout","output_type":"stream","text":["54/54 [==============================] - 17s 308ms/step - loss: 0.3583 - tp: 774.0000 - fp: 22.0000 - tn: 842.0000 - fn: 90.0000 - accuracy: 0.9352 - precision: 0.9724 - recall: 0.8958 - auc: 0.9558\n","Validation accuracy: 93.5185194015503%\n"]}],"source":["# Validation Set\n","evaluation_results = model_original_HVoice.evaluate(valid_generator_HVoice)\n","print(f'Validation accuracy: {evaluation_results[5] * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xL0NcYxGXoq","outputId":"6920aeb9-922b-4208-c627-ae5aa0844572","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 213s 8s/step - loss: 0.0838 - tp: 368.0000 - fp: 4.0000 - tn: 448.0000 - fn: 16.0000 - accuracy: 0.9761 - precision: 0.9892 - recall: 0.9583 - auc: 0.9917\n","Test accuracy: 97.60765433311462%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","evaluation_results = model_original_HVoice.evaluate(test_generator_HVoice)\n","print(f'Test accuracy: {evaluation_results[5] * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_original_HVoice.predict(test_generator_HVoice) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_HVoice.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kt1KyM8UuZQt","outputId":"55451c98-0014-4c09-b70a-8e2097627e79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 136ms/step\n","FPR: 42.92035398230089%\n"]}]},{"cell_type":"markdown","metadata":{"id":"HlDF_gMCSUv5","tags":[]},"source":["### Our-HVoice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1K34RGMSbzY"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice.keras'\n","loaded_model_our_HVoice = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upXkUfDGSn-Q","outputId":"b1faa10d-eee3-4526-ab7b-c36720025693","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["54/54 [==============================] - 7s 129ms/step - loss: 0.1897 - accuracy: 0.9410\n","Validation accuracy: 94.09722089767456%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = loaded_model_our_HVoice.evaluate(valid_generator_HVoice)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hErq7EN3GXor","colab":{"base_uri":"https://localhost:8080/"},"outputId":"de5c751e-acce-475d-c5a5-d61e1bcd34e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 136ms/step - loss: 0.1131 - accuracy: 0.9773\n","Test accuracy: 97.72727489471436%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = loaded_model_our_HVoice.evaluate(test_generator_HVoice)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = loaded_model_our_HVoice.predict(test_generator_HVoice) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_HVoice.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ew808eXwujcj","outputId":"863cc559-fa94-4c9a-ff79-1e7d664b43bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 130ms/step\n","FPR: 47.34513274336283%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"76Ah8SPvJUH7"},"source":["### Our-HVoice-Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97NMfAgtJUIE"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice-Dropout.keras'\n","loaded_model_our_HVoice_Dropout = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0019e2cb-e4a6-46f6-84b6-91fc45d7b379","tags":[],"id":"GUKxNP0-JUIE"},"outputs":[{"output_type":"stream","name":"stdout","text":["54/54 [==============================] - 7s 124ms/step - loss: 0.2309 - accuracy: 0.9265\n","Validation accuracy: 92.65046119689941%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = loaded_model_our_HVoice_Dropout.evaluate(valid_generator_HVoice)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fdebcd29-7937-42f7-8e45-5c3e75d0438f","id":"6zGp44nsJUIE"},"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 133ms/step - loss: 0.1905 - accuracy: 0.9318\n","Test accuracy: 93.18181872367859%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = loaded_model_our_HVoice_Dropout.evaluate(test_generator_HVoice)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = loaded_model_our_HVoice_Dropout.predict(test_generator_HVoice) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_HVoice.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pIIqY3Xjuszv","outputId":"7580ddac-3deb-42c8-b5e0-8eb2185f4a11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 132ms/step\n","FPR: 48.89380530973451%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"ALMaNSYUNATP"},"source":["### Our-HVoice-Deep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdhepfXBNATi"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice-Deep.keras'\n","loaded_model_our_HVoice_Deep = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"73b66278-adbc-4351-b67e-434cd873da2d","tags":[],"id":"-9EufpwNNATk"},"outputs":[{"output_type":"stream","name":"stdout","text":["54/54 [==============================] - 7s 131ms/step - loss: 0.6933 - accuracy: 0.5000\n","Validation accuracy: 50.0%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = loaded_model_our_HVoice_Deep.evaluate(valid_generator_HVoice)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b98a057b-fa28-4118-a409-1783bf5d47fe","id":"AHKNKSwuNATl"},"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 138ms/step - loss: 0.6919 - accuracy: 0.5407\n","Test accuracy: 54.066985845565796%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = loaded_model_our_HVoice_Deep.evaluate(test_generator_HVoice)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = loaded_model_our_HVoice_Deep.predict(test_generator_HVoice) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_HVoice.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQkj3FWCuzZi","outputId":"a2a01ca1-4749-474e-be2f-43a48aa416f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 139ms/step\n","FPR: 0.0%\n"]}]},{"cell_type":"markdown","metadata":{"id":"KzpITJxcSIQg","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["### Our-SiF-Regular\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"er00V4Ch5_eI"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular.keras'\n","loaded_model_our_SiF_regular = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKtPOCFvTXHm","outputId":"6f024cfe-8556-4197-b1a9-ba8885aa0bbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["54/54 [==============================] - 7s 133ms/step - loss: 2.5095 - accuracy: 0.4907\n","Validation accuracy: 49.07407462596893%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = loaded_model_our_SiF_regular.evaluate(valid_generator_HVoice)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HnoLpbnn56au","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6388b380-38e5-4465-c950-24c70fc57212"},"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 137ms/step - loss: 0.7999 - accuracy: 0.5371\n","Test accuracy: 53.70813608169556%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = loaded_model_our_SiF_regular.evaluate(test_generator_HVoice)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = loaded_model_our_SiF_regular.predict(test_generator_HVoice) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_HVoice.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QfjoZR6qvM9A","outputId":"67797959-52f5-4df7-8d9e-533178bc0ce3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 141ms/step\n","FPR: 28.539823008849556%\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"IF9Rt5xGJiOr"},"source":["### Our-SiF-Regular-Dropout\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dg1ZK9DAJiO1"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular-Dropout.keras'\n","loaded_model_our_SiF_regular_Dropout = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"077ac08d-a56a-4445-bc48-889e6dcda520","id":"w1xh_HFQJiO2"},"outputs":[{"output_type":"stream","name":"stdout","text":["54/54 [==============================] - 7s 130ms/step - loss: 1.7059 - accuracy: 0.5017\n","Validation accuracy: 50.17361044883728%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = loaded_model_our_SiF_regular_Dropout.evaluate(valid_generator_HVoice)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd0415f6-f93c-48b4-cc72-e36b6c031dc3","id":"Nrt3phSNJiO2"},"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 132ms/step - loss: 0.7334 - accuracy: 0.5538\n","Test accuracy: 55.38277626037598%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = loaded_model_our_SiF_regular_Dropout.evaluate(test_generator_HVoice)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = loaded_model_our_SiF_regular_Dropout.predict(test_generator_HVoice) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_HVoice.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWvCFOxpvW2u","outputId":"fd0c59db-8a8b-468f-f150-e7110aed8d13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 133ms/step\n","FPR: 20.13274336283186%\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"JXUTa9jANLHA"},"source":["### Our-SiF-Regular-Deep\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYXlv3E1NLHW"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Regular-Deep.keras'\n","loaded_model_our_SiF_regular_Deep = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c92a97be-30e1-47aa-9b6b-4093d9335463","id":"UakF1KYNNLHW"},"outputs":[{"output_type":"stream","name":"stdout","text":["54/54 [==============================] - 7s 129ms/step - loss: 1.9961 - accuracy: 0.5191\n","Validation accuracy: 51.90972089767456%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = loaded_model_our_SiF_regular_Deep.evaluate(valid_generator_HVoice)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cee05161-0a88-4af3-86f7-73761926c6a5","id":"-QSbYW4BNLHX"},"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 133ms/step - loss: 1.1060 - accuracy: 0.5478\n","Test accuracy: 54.78469133377075%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = loaded_model_our_SiF_regular_Deep.evaluate(test_generator_HVoice)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = loaded_model_our_SiF_regular_Deep.predict(test_generator_HVoice) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_HVoice.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sy5qkmkTve07","outputId":"d48a0911-74cf-447f-a7dc-facd6cd43883"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 131ms/step\n","FPR: 0.6637168141592921%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"V_ZcsrwuC9E5"},"source":["### Our-SiF-Filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0QOzuV1C9FX"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-SiF-Filtered.keras'\n","model_our_SiF_filtered = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"95b0aa43-b7f7-489c-84ed-18876b1ce894","id":"bQgxK9OAC9FY","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["54/54 [==============================] - 7s 134ms/step - loss: 3.5084 - accuracy: 0.4815\n","Validation accuracy: 48.148149251937866%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_SiF_filtered.evaluate(valid_generator_HVoice)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"05779dd5-06e9-44ca-e382-e2b44a73c4be","id":"IsrVaOp_C9FZ","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 134ms/step - loss: 0.9036 - accuracy: 0.4928\n","Test accuracy: 49.28229749202728%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_SiF_filtered.evaluate(test_generator_HVoice)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_SiF_filtered.predict(test_generator_HVoice) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_HVoice.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1QEDhqSFvmtX","outputId":"fe906146-816b-424e-ecd4-62a651a56a10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 147ms/step\n","FPR: 73.23008849557522%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"_KRlVdolJQ54"},"source":["### Our-HVoice_SiF-Regular"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NA3yVecqJQ6U"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice_SiF-Regular.keras'\n","model_our_HVoice_SiF_Regular = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"e1758cae-aee9-4910-cc7e-b837a11b72e6","id":"h9gzgUDfJQ6U","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["54/54 [==============================] - 7s 131ms/step - loss: 0.2084 - accuracy: 0.9334\n","Validation accuracy: 93.34490895271301%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice_SiF_Regular.evaluate(valid_generator_HVoice)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"325b8b5e-619b-48aa-8ec4-a301460d8a9b","id":"Loarcgj7JQ6V","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 3s 128ms/step - loss: 0.1911 - accuracy: 0.9593\n","Test accuracy: 95.9330141544342%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice_SiF_Regular.evaluate(test_generator_HVoice)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice_SiF_Regular.predict(test_generator_HVoice) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_HVoice.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRRFfqLMvtql","outputId":"26e0365a-c474-46b8-fbe1-894c2ae9adfa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 142ms/step\n","FPR: 45.35398230088495%\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"zR3v9bOXJQ6W"},"source":["### Our-HVoice_SiF-Filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5WRipuhCJQ6W","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e52a96b-c010-4084-e727-b48d9c241f6a"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Skipping variable loading for optimizer 'RMSprop', because it has 11 variables whereas the saved optimizer has 1 variables. \n"]}],"source":["from tensorflow.keras.models import load_model\n","\n","# ---------- Load our saved model ---------- #\n","model_path = root_dir + 'Voice_Cloning_Detection/Models/Deep4SNet-Our-HVoice_SiF-Filtered.keras'\n","model_our_HVoice_SiF_Filtered = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"3d2d696a-fea5-4ffb-feb8-6df677106b55","id":"7NTBbeQ3JQ6X","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["54/54 [==============================] - 8s 137ms/step - loss: 0.1900 - accuracy: 0.9427\n","Validation accuracy: 94.27083134651184%\n"]}],"source":["# Validation Set\n","loss_val, accuracy_val = model_our_HVoice_SiF_Filtered.evaluate(valid_generator_HVoice)\n","print(f'Validation accuracy: {accuracy_val * 100}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"7339d164-5bcf-49a6-f446-4d1692b7a42b","id":"HwZF6_UjJQ6X","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 4s 131ms/step - loss: 0.1155 - accuracy: 0.9868\n","Test accuracy: 98.68420958518982%\n","FPR: 98.9247311827957%\n"]}],"source":["# Test set\n","loss_test, accuracy_test = model_our_HVoice_SiF_Filtered.evaluate(test_generator_HVoice)\n","print(f'Test accuracy: {accuracy_test * 100}%')\n","\n","# Compute false positive rate (FPR)\n","TP = evaluation_results[0]\n","FP = evaluation_results[1]\n","TN = evaluation_results[2]\n","FN = evaluation_results[3]\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"]},{"cell_type":"code","source":["# FPR\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for the test set\n","y_pred_proba = model_our_HVoice_SiF_Filtered.predict(test_generator_HVoice) # ----- CHANGE for Models ---------------\n","\n","# Convert probabilities to binary predictions (0 or 1) based on a threshold\n","threshold = 0.5  # You can adjust this threshold if needed\n","y_pred_binary = (y_pred_proba > threshold).astype(int)\n","\n","# Get true labels for the test set\n","y_true = test_generator_HVoice.classes # ----- CHANGE for Models ---------------\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_binary)\n","\n","# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","TP = conf_matrix[1, 1]\n","\n","# Compute false positive rate (FPR)\n","FPR = FP / (FP + TN)\n","print(f'FPR: {FPR * 100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3A_JbQN1vzU9","outputId":"a2dda9f1-3bc1-4eb7-c927-b6e81ddc8579"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 3s 128ms/step\n","FPR: 44.02654867256637%\n"]}]}],"metadata":{"colab":{"collapsed_sections":["fXJpfi1R7AQC","SP8zoYANqAgX","BZ2YQ9HPrm1J","tppoDtKQqKEb","8CDdpwbLWWxP","1bmQ901jpe1r","lsdLY8yfEu7L","gtJn2rwv39kh","RHh3JfxXIv3b","lPXtZH-CG4n1","rgeyLRvlLgSI","voBmG2uow6kP","93SySYw8xFXv","uK7d1mxgwKZd","7EAw8uU2HZo9","tHytz4CBL00Y","wl86mtOmGXoi","SwbcwwDFIwO-","gvplpdqjMDKc","f4NjIFYsGXon","aHfJEvjJHyoA","TIfqqA5HIU7S","wuaOu1FRGXoo","5YYGtkcwGXoo","AR9CVmGXJBM-","VCNAcnJmMfnw","YD_vv_nLCfuZ","5CGVDJ5aJI9G","JVth1xbEM3_H","vumLB2zWCsJy","e9DzEm7jI07Y","akl3VVCkI072","qsg-tPW2V4KC","HlDF_gMCSUv5","76Ah8SPvJUH7","ALMaNSYUNATP","KzpITJxcSIQg","IF9Rt5xGJiOr","JXUTa9jANLHA","V_ZcsrwuC9E5","_KRlVdolJQ54","zR3v9bOXJQ6W"],"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}